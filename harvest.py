import os
import psycopg2
from bs4 import BeautifulSoup
import requests
from datetime import datetime

DATABASE_URL = os.environ.get("DATABASE_URL")

def init_db():
    conn = psycopg2.connect(DATABASE_URL)
    cur = conn.cursor()
    cur.execute("""
        CREATE TABLE IF NOT EXISTS news (
            id SERIAL PRIMARY KEY,
            title TEXT,
            url TEXT,
            content TEXT,
            source TEXT,
            image_url TEXT,
            created_at TIMESTAMP
        )
    """)
    conn.commit()
    cur.close()
    conn.close()
    print("âœ… æ•°æ®åº“åˆå§‹åŒ–å®Œæˆ")

def save_news(title, url, content, source, image_url):
    try:
        conn = psycopg2.connect(DATABASE_URL)
        cur = conn.cursor()
        cur.execute("""
            INSERT INTO news (title, url, content, source, image_url, created_at)
            VALUES (%s,%s,%s,%s,%s,%s)
            ON CONFLICT DO NOTHING
        """, (title, url, content, source, image_url, datetime.now()))
        conn.commit()
        cur.close()
        conn.close()
        print(f"âœ… æ–°é—»ä¿å­˜æˆåŠŸ: {title}")
    except Exception as e:
        print("âŒ ä¿å­˜æ–°é—»å‡ºé”™:", e)

def rewrite_content(content):
    # è¿™é‡Œç®€å•è¿”å›åŸæ–‡ï¼Œå¯æ›¿æ¢ä¸º OpenAI æ”¹å†™é€»è¾‘
    return content

def fetch_news():
    print("ğŸŸ¢ å¼€å§‹æŠ“å–æ–°é—»...")
    init_db()
    url = "https://www.chinanews.com.cn/"
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64)"
    }

    try:
        resp = requests.get(url, headers=headers, timeout=30)
        resp.raise_for_status()
        print("ç½‘é¡µé•¿åº¦:", len(resp.text))
        soup = BeautifulSoup(resp.text, "lxml")

        # é’ˆå¯¹ä¸­æ–°ç½‘é¦–é¡µæ–°é—»åŒºåŸŸçš„ selector
        articles = soup.select("div.content_left a")[:5]  # æŠ“å–å‰5æ¡æ–°é—»

        if not articles:
            print("âš ï¸ æ²¡æœ‰æŠ“åˆ°æ–°é—»ï¼Œå¯èƒ½ selector éœ€è¦å†æ¬¡è°ƒæ•´")
            return

        for a in articles:
            title = a.get_text(strip=True)
            href = a.get("href")
            if not href.startswith("http"):
                href = "https://www.chinanews.com.cn" + href
            content = title
            rewritten = rewrite_content(content)
            img_tag = a.find("img")
            image_url = img_tag["src"] if img_tag else ""
            save_news(title, href, rewritten, "Chinanews", image_url)

        print("ğŸŸ¢ æŠ“å–å®Œæˆ")
    except Exception as e:
        print("âŒ æŠ“å–å‡ºé”™:", e)
        
def get_latest_news(limit=10):
    try:
        conn = psycopg2.connect(DATABASE_URL)
        cur = conn.cursor()
        cur.execute("""
            SELECT title, url, content, source, image_url, created_at
            FROM news ORDER BY created_at DESC LIMIT %s
        """, (limit,))
        rows = cur.fetchall()
        cur.close()
        conn.close()
        return [{"title": r[0], "url": r[1], "content": r[2], "source": r[3], "image_url": r[4], "created_at": str(r[5])} for r in rows]
    except Exception as e:
        print("âŒ æŸ¥è¯¢æ–°é—»å‡ºé”™:", e)
        return []
