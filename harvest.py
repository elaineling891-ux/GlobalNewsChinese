def fetch_news():
    print("ğŸŸ¢ å¼€å§‹æŠ“å–æ–°é—»...")
    init_db()

    try:
        conn_test = psycopg2.connect(DATABASE_URL)
        print("âœ… fetch_news: æ•°æ®åº“è¿æ¥æˆåŠŸ")
        conn_test.close()
    except Exception as e:
        print("âŒ fetch_news: æ•°æ®åº“è¿æ¥å¤±è´¥", e)
        return

    url = "https://www.chinanews.com.cn/"
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64)"
    }

    try:
        resp = requests.get(url, headers=headers, timeout=30)
        resp.raise_for_status()
        print("ç½‘é¡µé•¿åº¦:", len(resp.text))
        soup = BeautifulSoup(resp.text, "lxml")

        # é€‰ä¸­æ–°ç½‘é¡µæ–°é—»åˆ—è¡¨ï¼Œä¿è¯å¯ä»¥æŠ“åˆ°
        # æ³¨æ„ï¼šè¿™ä¸ª selector éœ€è¦æ ¹æ®ç½‘ç«™å®é™…ç»“æ„è°ƒæ•´
        articles = soup.select("div.content_list a")[:5]  # æŠ“å‰5æ¡æ–°é—»

        if not articles:
            print("âš ï¸ æ²¡æœ‰æŠ“åˆ°æ–°é—»ï¼Œå¯èƒ½ selector éœ€è¦è°ƒæ•´")
        for a in articles:
            title = a.get_text(strip=True)
            href = a['href']
            if not href.startswith("http"):
                href = "https://www.chinanews.com.cn" + href
            content = title
            rewritten = rewrite_content(content)
            img_tag = a.find("img")
            image_url = img_tag['src'] if img_tag else ""
            save_news(title, href, rewritten, "Chinanews", image_url)

        print("ğŸŸ¢ æŠ“å–å®Œæˆ")
    except Exception as e:
        print("âŒ æŠ“å–å‡ºé”™:", e)
